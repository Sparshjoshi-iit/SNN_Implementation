{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b302e74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omniglot dataset loaded.\n",
      "Training samples: 19280\n",
      "Test samples: 13180\n",
      "Image shape: torch.Size([1, 105, 105])\n",
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a transformation to convert images to tensors and normalize\n",
    "# The paper uses 105x105 images. Torchvision provides them at this size.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "# Note: Omniglot's 'background' set is for training, 'evaluation' is for testing.\n",
    "omniglot_train = datasets.Omniglot(\n",
    "    root=\"./data\",\n",
    "    background=True,  # Use the background set for training\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "omniglot_test = datasets.Omniglot(\n",
    "    root=\"./data\",\n",
    "    background=False, # Use the evaluation set for testing\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Omniglot dataset loaded.\")\n",
    "print(f\"Training samples: {len(omniglot_train)}\")\n",
    "print(f\"Test samples: {len(omniglot_test)}\")\n",
    "\n",
    "image, label = omniglot_train[0]\n",
    "print(\"Image shape:\", image.shape) # Shape: [Channels, Height, Width]\n",
    "print(\"Label:\", label)\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d13be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SiameseOmniglot(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for creating pairs of images for the Siamese network.\n",
    "    It will generate a positive pair (same class) or a negative pair\n",
    "    (different class) for each sample.\n",
    "    \"\"\"\n",
    "    def __init__(self,omniglot_dataset):\n",
    "        self.omniglot_dataset=omniglot_dataset\n",
    "        self.labels = np.array([label for _, label in self.omniglot_dataset])\n",
    "        self.label_map = {label: np.where(self.labels == label)[0] for label in np.unique(self.labels)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.omniglot_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = self.omniglot_dataset[index]\n",
    "\n",
    "        # Randomly decide whether to create a positive (1) or negative (0) pair\n",
    "        should_get_positive = random.randint(0, 1)\n",
    "\n",
    "        if should_get_positive:\n",
    "            # Get a second image from the SAME class\n",
    "            positive_indices = self.label_map[label1]\n",
    "            idx2 = random.choice(positive_indices)\n",
    "            # Ensure the second image is not the same as the first\n",
    "            while idx2 == index:\n",
    "                idx2 = random.choice(positive_indices)\n",
    "            img2, _ = self.omniglot_dataset[idx2]\n",
    "            label = torch.tensor(1.0) # Label for \"same class\" is 1\n",
    "        else:\n",
    "            # Get a second image from a DIFFERENT class\n",
    "            negative_label = random.choice(list(self.label_map.keys()))\n",
    "            while negative_label == label1:\n",
    "                negative_label = random.choice(list(self.label_map.keys()))\n",
    "\n",
    "            negative_indices = self.label_map[negative_label]\n",
    "            idx2 = random.choice(negative_indices)\n",
    "            img2, _ = self.omniglot_dataset[idx2]\n",
    "            label = torch.tensor(0.0) # Label for \"different class\" is 0\n",
    "\n",
    "        return img1, img2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ea5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_train_dataset = SiameseOmniglot(omniglot_train)\n",
    "siamese_test_dataset = SiameseOmniglot(omniglot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365b6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_train_dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=64) # Batch size can be tuned\n",
    "\n",
    "test_dataloader = DataLoader(siamese_test_dataset,\n",
    "                            shuffle=False,\n",
    "                            batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de587c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the dataloader\n",
    "img1_batch, img2_batch, labels_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Get the first pair from the batch\n",
    "img1, img2, label = img1_batch[0], img2_batch[0], labels_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcec2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the pair\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "ax1.imshow(img1.squeeze(), cmap='gray')\n",
    "ax1.set_title('Image 1')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(img2.squeeze(), cmap='gray')\n",
    "ax2.set_title('Image 2')\n",
    "ax2.axis('off')\n",
    "plt.suptitle(f'Label: {\"Same Class\" if label == 1.0 else \"Different Class\"}', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9774c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese Network Model:\n",
      "SiameseNN(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (10): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "--------------------\n",
      "Model is on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SiameseNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNN,self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(1, 64, kernel_size=10), # Input channels = 1 (grayscale)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            # Layer 2\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            # Layer 3\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            # Layer 4\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # The output of the CNN is a 256x6x6 feature map.\n",
    "        # We flatten this and pass it to a fully connected layer.\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.Sigmoid() # As specified in the paper\n",
    "        )\n",
    "        # The final classifier layer takes the distance vector and outputs a similarity score\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        \"\"\"Passes one image through the twin network to get its feature vector.\"\"\"\n",
    "        # Pass input through the convolutional layers\n",
    "        output = self.cnn(x)\n",
    "        \n",
    "        # Flatten the feature map to a 1D vector\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        \n",
    "        # Pass through the fully connected layer to get the final feature vector\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        \"\"\"Processes a pair of images.\"\"\"\n",
    "        # Get the feature vector for each image in the pair\n",
    "        feature_vector1 = self.forward_one(img1)\n",
    "        feature_vector2 = self.forward_one(img2)\n",
    "\n",
    "        # Calculate the L1 distance between the two feature vectors\n",
    "        distance = torch.abs(feature_vector1 - feature_vector2)\n",
    "        \n",
    "        # Pass the distance to the classifier to get the final similarity score\n",
    "        similarity_score = self.classifier(distance)\n",
    "        \n",
    "        return similarity_score\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseNN().to(device)\n",
    "\n",
    "print(\"Siamese Network Model:\")\n",
    "print(model)\n",
    "print(\"-\" * 20)\n",
    "print(f\"Model is on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b11d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/10], Batch [50/302], Loss: 0.6264\n",
      "Epoch [1/10], Batch [100/302], Loss: 0.5752\n",
      "Epoch [1/10], Batch [150/302], Loss: 0.5581\n",
      "Epoch [1/10], Batch [200/302], Loss: 0.5323\n",
      "Epoch [1/10], Batch [250/302], Loss: 0.4932\n",
      "Epoch [1/10], Batch [300/302], Loss: 0.4841\n",
      "Epoch [2/10], Batch [50/302], Loss: 0.4297\n",
      "Epoch [2/10], Batch [100/302], Loss: 0.3890\n",
      "Epoch [2/10], Batch [150/302], Loss: 0.3706\n",
      "Epoch [2/10], Batch [200/302], Loss: 0.3446\n",
      "Epoch [2/10], Batch [250/302], Loss: 0.3141\n",
      "Epoch [2/10], Batch [300/302], Loss: 0.3033\n",
      "Epoch [3/10], Batch [50/302], Loss: 0.2949\n",
      "Epoch [3/10], Batch [100/302], Loss: 0.2719\n",
      "Epoch [3/10], Batch [150/302], Loss: 0.2848\n",
      "Epoch [3/10], Batch [200/302], Loss: 0.2649\n",
      "Epoch [3/10], Batch [250/302], Loss: 0.2650\n",
      "Epoch [3/10], Batch [300/302], Loss: 0.2517\n",
      "Epoch [4/10], Batch [50/302], Loss: 0.2562\n",
      "Epoch [4/10], Batch [100/302], Loss: 0.2104\n",
      "Epoch [4/10], Batch [150/302], Loss: 0.2335\n",
      "Epoch [4/10], Batch [200/302], Loss: 0.2131\n",
      "Epoch [4/10], Batch [250/302], Loss: 0.1992\n",
      "Epoch [4/10], Batch [300/302], Loss: 0.2222\n",
      "Epoch [5/10], Batch [50/302], Loss: 0.2008\n",
      "Epoch [5/10], Batch [100/302], Loss: 0.2063\n",
      "Epoch [5/10], Batch [150/302], Loss: 0.1891\n",
      "Epoch [5/10], Batch [200/302], Loss: 0.1733\n",
      "Epoch [5/10], Batch [250/302], Loss: 0.1854\n",
      "Epoch [5/10], Batch [300/302], Loss: 0.1721\n",
      "Epoch [6/10], Batch [50/302], Loss: 0.2006\n",
      "Epoch [6/10], Batch [100/302], Loss: 0.1791\n",
      "Epoch [6/10], Batch [150/302], Loss: 0.1492\n",
      "Epoch [6/10], Batch [200/302], Loss: 0.1639\n",
      "Epoch [6/10], Batch [250/302], Loss: 0.1625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for i, (img1, img2, label) in enumerate(train_dataloader, 1):\n",
    "        # Move tensors to the configured device\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted output by passing inputs to the model\n",
    "        output = model(img1, img2)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(output, label.unsqueeze(1))\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:  # Print every 50 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i}/{len(train_dataloader)}], Loss: {running_loss / 50:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# --- 3. Save the trained model (optional) ---\n",
    "torch.save(model.state_dict(), \"siamese_model.pth\")\n",
    "print(\"Model saved to siamese_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abba56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"siamese_model.pth\"))\n",
    "model.eval()\n",
    "print(\"Trained model loaded successfully.\")\n",
    "test_labels = np.array([label for _, label in omniglot_test])\n",
    "unique_labels = np.unique(test_labels)\n",
    "selected_labels = np.random.choice(unique_labels, size=20, replace=False)\n",
    "\n",
    "# From the first selected class, pick two images.\n",
    "# One will be the \"test image\", the other will be the \"correct answer\".\n",
    "label_map_test = {label: np.where(test_labels == label)[0] for label in unique_labels}\n",
    "\n",
    "class_indices = label_map_test[selected_labels[0]]\n",
    "anchor_idx, correct_support_idx = np.random.choice(class_indices, size=2, replace=False)\n",
    "\n",
    "test_image, _ = omniglot_test[anchor_idx]\n",
    "correct_image, _ = omniglot_test[correct_support_idx]\n",
    "# Create the \"support set\" of N=20 images\n",
    "support_set = []\n",
    "support_set.append(correct_image) # The first image is the correct one\n",
    "\n",
    "# Add 19 other \"imposter\" images from different classes\n",
    "for label in selected_labels[1:]:\n",
    "    imposter_idx = np.random.choice(label_map_test[label])\n",
    "    imposter_image, _ = omniglot_test[imposter_idx]\n",
    "    support_set.append(imposter_image)\n",
    "\n",
    "# Shuffle the support set so the correct answer isn't always first\n",
    "random.shuffle(support_set)\n",
    "\n",
    "\n",
    "# --- 3. Perform the One-Shot Comparison ---\n",
    "similarities = []\n",
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    # Move test image to the device and add a batch dimension\n",
    "    test_image_tensor = test_image.unsqueeze(0).to(device)\n",
    "\n",
    "    for support_image in support_set:\n",
    "        # Move support image to the device and add a batch dimension\n",
    "        support_image_tensor = support_image.unsqueeze(0).to(device)\n",
    "\n",
    "        # Use the model to get the similarity score\n",
    "        # Note: We are now using the model for inference, not training\n",
    "        similarity = model(test_image_tensor, support_image_tensor)\n",
    "        similarities.append(similarity.item())\n",
    "\n",
    "\n",
    "# --- 4. Get the Prediction ---\n",
    "prediction_idx = np.argmax(similarities)\n",
    "prediction_is_correct = (support_set[prediction_idx] == correct_image)\n",
    "\n",
    "\n",
    "# --- 5. Visualize the Results ---\n",
    "fig, axes = plt.subplots(3, 7, figsize=(15, 8))\n",
    "fig.suptitle(f'One-Shot Prediction: {\"Correct!\" if prediction_is_correct else \"Incorrect!\"}',\n",
    "             fontsize=16, color='green' if prediction_is_correct else 'red')\n",
    "\n",
    "# Plot the test image\n",
    "ax = axes[0, 3]\n",
    "ax.imshow(test_image.squeeze(), cmap='gray')\n",
    "ax.set_title(\"Test Image\")\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot the support set images\n",
    "for i, (ax, img) in enumerate(zip(axes.flat[7:], support_set)):\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Sim: {similarities[i]:.2f}\", fontsize=10)\n",
    "    ax.axis('off')\n",
    "    if i == prediction_idx: # Highlight the model's prediction\n",
    "        rect = plt.Rectangle(ax.get_position().bounds, edgecolor='blue',facecolor='none', lw=3, transform=fig.transFigure)\n",
    "        fig.patches.append(rect)\n",
    "    if img == correct_image: # Highlight the ground truth\n",
    "        rect = plt.Rectangle(ax.get_position().bounds, edgecolor='green',facecolor='none', lw=3, ls='--', transform=fig.transFigure)\n",
    "        fig.patches.append(rect)\n",
    "\n",
    "# Hide unused axes\n",
    "for i in range(7):\n",
    "    axes[0, i].axis('off')\n",
    "    if i < 3 or i > 3: axes[0, i].set_visible(False)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ce0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
